import streamlit as st # web arayÃ¼zÃ¼ oluÅŸturmak iÃ§in bir python kÃ¼tÃ¼phanesi

from langchain_google_genai import ChatGoogleGenerativeAI #langchain google modulleri: chat llm 
from langchain_huggingface import HuggingFaceEmbeddings


from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader

from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

from dotenv import load_dotenv
import os 
import tempfile # geÃ§ici dosya iÅŸlemleri iÃ§in

# .env dosyasÄ±ndan yÃ¼kleme iÅŸlemlerini gereÃ§ekleÅŸtir ilk olarak load_dotenv
load_dotenv()
os.environ["GOOGLE_API_KEY"] = os.getenv("GEMINI_API_KEY") 

# streamlit sayfa baÅŸlÄ±ÄŸÄ±nÄ± ve ikonunu ayarla 
st.set_page_config(page_title= "MÃ¼ÅŸteri Destek Botu", page_icon= "ğŸ¤–")  # streamlit set page yani sayfa ayarÄ± yapÄ±lan konfigÃ¼rasyon dosyasÄ±
st.title("PDF Destek Botu (RAG + Memory)")
st.write("Bir pdf yÃ¼kleyin, iÃ§eriÄŸine dair sorular sorun. TÃ¼rkÃ§e desteklidir.")

# pdf yÃ¼kleme bileÅŸeni
uploaded_file = st.file_uploader("PDF dosyanÄ±zÄ± yÃ¼kleyin.", type= "pdf", key= "pdf_uploader")

# eÄŸer kullanÄ±cÄ± yeni bir pdf yÃ¼klediyse ve daha Ã¶nce yuklenen ile aynÄ± deÄŸilse
if uploaded_file is not None:
    if "last_uploaded_name" not in st.session_state or uploaded_file.name != st.session_state.last_uploaded_name:
        #kullanÄ±cya iÅŸleniyor bilgisi gÃ¶nderelim
        with st.spinner("PDF iÅŸleniyor..."):
            #yÃ¼klenen pdf i gecici bir dosyaya yazdÄ±r
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(uploaded_file.read())
                tmp_path = tmp.name # geÃ§ici dosyanÄ±n yolu 
            # PyPDfLoader ile pdf iÃ§eriÄŸini yÃ¼kle
            loader = PyPDFLoader(tmp_path)
            documents = loader.load()

            # metinleri parÃ§ala yani chunklara bÃ¶l
            splitter = RecursiveCharacterTextSplitter(chunk_size= 500, chunk_overlap= 50)
            docs = splitter.split_documents(documents)

            # HuggingfaceEmbedding ile vektÃ¶rleÅŸtirme 
            embedding = HuggingFaceEmbeddings(model_name ="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

            #FAISS ile vektÃ¶r veri tabanÄ±
            vector_db  = FAISS.from_documents(docs, embedding)

            # memory ve gemini 1.5 ile llm oluÅŸturma
            memory = ConversationBufferMemory(memory_key = "chat_history", return_messages=True)
            llm = ChatGoogleGenerativeAI(model = "gemini-1.5-flash", temperature = 0)

            # rag + memory zincirini oluÅŸturma
            qa_chain = ConversationalRetrievalChain.from_llm(
                llm = llm,
                retriever = vector_db.as_retriever(search_kwargs = {"k": 3}),
                memory = memory 
            )

            st.session_state.qa_chain = qa_chain
            st.session_state.chat_history = []
            st.session_state.last_uploaded_name = uploaded_file.name # aynÄ± dosyanÄ±n yeniden iÅŸlenmesini engellemek iÃ§in    

        st.success("Pdf baÅŸarÄ±yla iÅŸlendi.")      

if "qa_chain" in st.session_state:  # eÄŸer pdf iÅŸlendiyse 
    #kullanÄ±cÄ±n sorusunu alÄ±r
    user_question = st.text_input ("ğŸ’ğŸ» Sorunuzu yazÄ±nÄ±z: ")

    if user_question:
        response = st.session_state.qa_chain.invoke(user_question) # langchain zincirine soruyu gÃ¶nder
        st.session_state.chat_history.append(("ğŸ’ğŸ»", user_question))  # kullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekleme
        st.session_state.chat_history.append(("ğŸ¤–", response["answer"])) # model yanÄ±tÄ±nÄ± historye ekleme

    if st.session_state.chat_history:
        st.subheader("ğŸ“‹ Sohbet GeÃ§miÅŸi")
        for sender, msg in st.session_state.chat_history:
            st.markdown(f"**{sender}**: {msg}" )